{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH540yEwYgLM",
        "outputId": "509970c3-f511-454d-bea1-058ae60696a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.10.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2137.6 MB)\n",
            "\u001b[K     |████████████▌                   | 834.1 MB 1.4 MB/s eta 0:15:03tcmalloc: large alloc 1147494400 bytes == 0x39e5a000 @  0x7faf6b395615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |███████████████▉                | 1055.7 MB 38.4 MB/s eta 0:00:29tcmalloc: large alloc 1434370048 bytes == 0x7e4b0000 @  0x7faf6b395615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████            | 1336.2 MB 1.4 MB/s eta 0:09:36tcmalloc: large alloc 1792966656 bytes == 0x32e2000 @  0x7faf6b395615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |█████████████████████████▎      | 1691.1 MB 1.3 MB/s eta 0:05:40tcmalloc: large alloc 2241208320 bytes == 0x6e0ca000 @  0x7faf6b395615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████████████████| 2137.6 MB 1.3 MB/s eta 0:00:01tcmalloc: large alloc 2137645056 bytes == 0xf3a2c000 @  0x7faf6b3941e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n",
            "tcmalloc: large alloc 2672058368 bytes == 0x1e754e000 @  0x7faf6b395615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n",
            "\u001b[K     |████████████████████████████████| 2137.6 MB 406 bytes/s \n",
            "\u001b[?25hCollecting torchvision==0.11.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.11.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (21.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.9 MB 1.7 MB/s \n",
            "\u001b[?25hCollecting torchaudio==0.10.0\n",
            "  Downloading https://download.pytorch.org/whl/rocm4.1/torchaudio-0.10.0%2Brocm4.1-cp37-cp37m-linux_x86_64.whl (2.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 50.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0+cu111) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.0+cu111) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.0+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.12.0+cu113\n",
            "    Uninstalling torchvision-0.12.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.12.0+cu113\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.11.0+cu113\n",
            "    Uninstalling torchaudio-0.11.0+cu113:\n",
            "      Successfully uninstalled torchaudio-0.11.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.10.0+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.10.0+cu111 torchaudio-0.10.0+rocm4.1 torchvision-0.11.0+cu111\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.10.0+cu111 torchvision==0.11.0+cu111 torchaudio==0.10.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjHnmUM2lzZe",
        "outputId": "cde1fa1b-89ec-4a46-cd4e-9ca5442720e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.9 MB 6.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 33.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 25.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 750 kB 38.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 407 kB 9.9 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 584 kB 9.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 136 kB 53.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 409 kB 46.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 49.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 44.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 51.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 55.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 491 kB/s \n",
            "\u001b[?25hRequirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.8.2)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: pyDeprecate==0.3.* in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (0.3.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.8)\n"
          ]
        }
      ],
      "source": [
        " # Install required packages.\n",
        "!pip install -q torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install -q pytorch-lightning\n",
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tt2uSP44QNWj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLZWm9HChwWN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F \n",
        "import torch_geometric.transforms as T\n",
        "import torch.optim as optim\n",
        "import torchmetrics\n",
        "from torch.optim import lr_scheduler\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.data import DataLoader\n",
        "import torch_geometric.nn\n",
        "from torch_geometric.nn import GraphConv, TopKPooling, SplineConv\n",
        "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from pytorch_lightning.loggers import TensorBoardLogger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eps3t4gGbEZ"
      },
      "outputs": [],
      "source": [
        "from math import sin, cos\n",
        "import copy\n",
        "import random\n",
        "\n",
        "def rotation(graph):\n",
        "  theta = np.random.uniform(-Theta, Theta)\n",
        "  a = np.array([[cos(theta), -sin(theta)],\n",
        "                [sin(theta), cos(theta)]])\n",
        "  \n",
        "  g = graph.edge_attr[:,:2]\n",
        "  p = np.apply_along_axis(np.dot, 1, g, a)\n",
        "  graph.edge_attr[:,:2] = torch.from_numpy(p[:,:2])\n",
        "  return graph\n",
        "\n",
        "def scaling(graph):\n",
        "  s = np.random.uniform(1/S, S, size=2)\n",
        "  a = np.array([[s[0], 0],\n",
        "                [0, s[1]]])\n",
        "  \n",
        "  g = graph.edge_attr[:,:2]\n",
        "  p = np.apply_along_axis(np.dot, 1, g, a)\n",
        "  graph.edge_attr[:,:2] = torch.from_numpy(p[:,:2])\n",
        "  return graph\n",
        "\n",
        "def translation(p):\n",
        "  if p[0]==0 and p[1]==0:\n",
        "    return np.asarray(p)\n",
        "  else:\n",
        "    return np.asarray(p) + np.random.uniform(-TT, TT, size=2)\n",
        "\n",
        "# TT = 0.1;\n",
        "# Theta = 0.6;\n",
        "# S = 1.4;\n",
        "\n",
        "TT = 0;\n",
        "Theta = 0;\n",
        "S = 1;\n",
        "\n",
        "class my_affine_transforms(T.BaseTransform):\n",
        "  def __init__(self, args = []):\n",
        "    pass\n",
        "\n",
        "  def __call__(self, data: torch_geometric.data.data.Data):\n",
        "    data = rotation(data)\n",
        "    data = scaling(data)\n",
        "\n",
        "    data.edge_attr[:, :2] = torch.from_numpy(np.apply_along_axis(translation, 1, data.edge_attr[:, :2]))\n",
        "\n",
        "    # data.edge_attr[:, :2] = torch.from_numpy(np.apply_along_axis(trnsfrms, 1, data.edge_attr[:, :2]))\n",
        "    \n",
        "    # for p in data.edge_attr:\n",
        "    #   if p[0] != 0 or p[1] != 0:\n",
        "    #     p[:2] = torch.from_numpy(rotation(p[:2]))\n",
        "    #     p[:2] = torch.from_numpy(scaling(p[:2]))\n",
        "    #     p[:2] = torch.from_numpy(translation(p[:2]))\n",
        "    return data\n",
        "  \n",
        "  def __repr__(self) -> str:\n",
        "    return (f'{self.__class__.__name__}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCrvCm1QwPH5"
      },
      "outputs": [],
      "source": [
        "class my_normalization(T.BaseTransform):\n",
        "  def __init__(self, args = []):\n",
        "    pass\n",
        "\n",
        "  def my_norm(x, a, b):\n",
        "    return (x-a)/(b-a)\n",
        "\n",
        "  def __call__(self, data: torch_geometric.data.data.Data):\n",
        "    my_norm_vect = np.vectorize(my_normalization.my_norm)\n",
        "    x = np.array(data.edge_attr)\n",
        "    x[:,0] = my_norm_vect(x[:,0],  min(x[:,0]), max(x[:,0]))\n",
        "    x[:,1] = my_norm_vect(x[:,1],  min(x[:,1]), max(x[:,1]))\n",
        "    data.edge_attr[:, 0] = torch.from_numpy(x[:, 0])\n",
        "    data.edge_attr[:, 1] = torch.from_numpy(x[:, 1])\n",
        "    return data\n",
        "\n",
        "  def __repr__(self) -> str:\n",
        "    return (f'{self.__class__.__name__},')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9axYBYwvWDhG",
        "outputId": "c094bfd9-73a6-488f-fe3f-6500d3f78d8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/Cuneiform.zip\n",
            "Extracting data/TUDataset/Cuneiform/Cuneiform.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "dataset = TUDataset(root='data/TUDataset', name='Cuneiform', transform=T.Compose([my_normalization()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pum7xm-n4unn"
      },
      "outputs": [],
      "source": [
        "class Net(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # kernel_size = 5\n",
        "        kernel_size = 5\n",
        "\n",
        "        dim=dataset.num_edge_features\n",
        "        degree = 1\n",
        "\n",
        "        self.conv1 = SplineConv(dataset.num_features, 32, dim=dim, kernel_size=kernel_size, degree=degree)\n",
        "        self.conv2 = SplineConv(32, 64, dim=dim, kernel_size=kernel_size, degree=degree)\n",
        "        self.conv3 = SplineConv(64, 64, dim=dim, kernel_size=kernel_size, degree=degree)\n",
        "        \n",
        "        self.lin1 = torch.nn.Linear(64, dataset.num_classes)\n",
        "\n",
        "        self.dropout = 0.2\n",
        "\n",
        "        self.train_accuracy = torchmetrics.Accuracy()\n",
        "        self.val_accuracy = torchmetrics.Accuracy()\n",
        "        self.test_accuracy = torchmetrics.Accuracy()\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        pseudo = data.edge_attr\n",
        "\n",
        "        in_dropout = 0.2\n",
        "        # in_dropout = 0.5\n",
        "        # in_dropout = 0.3\n",
        "\n",
        "        x = F.elu(self.conv1(x, edge_index, pseudo))\n",
        "        x = F.dropout(x, in_dropout, training = self.training)\n",
        "        x = F.elu(self.conv2(x, edge_index, pseudo))\n",
        "        x = F.dropout(x, in_dropout, training = self.training)\n",
        "        x = F.elu(self.conv3(x, edge_index, pseudo))\n",
        "        # x = F.dropout(x, in_dropout, training = self.training)\n",
        "        \n",
        "        # x = F.elu(self.conv4(x, edge_index, pseudo))\n",
        "        # x = F.dropout(x, self.dropout, training = self.training)\n",
        "\n",
        "        x = gap(x, batch)\n",
        "\n",
        "        x = F.dropout(x, self.dropout, training = self.training)\n",
        "\n",
        "        x = F.log_softmax(self.lin1(x), dim=1)\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "      output = self(batch)\n",
        "      # loss = F.nll_loss(output, batch.y)\n",
        "      loss = F.cross_entropy(output, batch.y)\n",
        "      self.log('training_loss', loss, on_epoch=True, on_step=False)\n",
        "      self.log('train_acc_step', self.train_accuracy(output, batch.y))\n",
        "      return loss\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "      self.log('train_acc_epoch', self.train_accuracy.compute())\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "      optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
        "      # \"an initial learning rate of 0.01 and learning rate decay to 0.001 after 200 epochs\"\n",
        "      scheduler = lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=[200], gamma = 0.1)\n",
        "      return {\n",
        "        \"optimizer\": optimizer,\n",
        "        \"lr_scheduler\": scheduler\n",
        "      }\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "      output = self(batch)\n",
        "      # loss = F.nll_loss(output, batch.y)\n",
        "      loss = F.cross_entropy(output, batch.y)\n",
        "      self.log('val_loss', loss, on_epoch=True, on_step=False)\n",
        "      self.log('val_acc_step', self.val_accuracy(output, batch.y))\n",
        "      return loss\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "      self.log('val_acc_epoch', self.val_accuracy.compute())\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "      output = self(batch)\n",
        "      # loss = F.nll_loss(output, batch.y)\n",
        "      loss = F.cross_entropy(output, batch.y)\n",
        "      self.log('test_loss', loss, on_epoch=True, on_step=False)\n",
        "      self.log('test_acc_step', self.test_accuracy(output, batch.y))\n",
        "      return loss\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "      self.log('test_acc_epoch', self.test_accuracy.compute())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_ufXHm0cAdf",
        "outputId": "10f6efb3-ad48-4018-8cd9-6c8584de4ad6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Mar  7 17:32:07 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    32W / 250W |   1239MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNWnGrab-wGO"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir lightning_logs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TdpS2pA3wyU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from datetime import datetime\n",
        "p = '/content/drive/My Drive/results/' + str(datetime.now())+'.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8ean4hk2OPa",
        "outputId": "21393abf-f642-44ee-8ca1-ad744499198d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-znT8dAi4Qa"
      },
      "outputs": [],
      "source": [
        "!rm -r /content/checkpoints/\n",
        "k_folds = 10\n",
        "max_epochs = 300\n",
        "# 20000\n",
        "# 300\n",
        "results = []\n",
        "tstamps = []\n",
        "batch_size = 64\n",
        "\n",
        "TT = 0.1;\n",
        "Theta = 0.06;\n",
        "S = 2;  \n",
        "\n",
        "# TT = 0.1;\n",
        "# Theta = 0.6;\n",
        "# S = 1.04;\n",
        "\n",
        "\n",
        "early_stopping = False\n",
        "np_random = True\n",
        "kfold_random = True\n",
        "\n",
        "# kfold = KFold(n_splits=k_folds, shuffle=kfold_random, random_state=0)\n",
        "kfold = KFold(n_splits=k_folds, shuffle=kfold_random)\n",
        "\n",
        "dataset = TUDataset(root='data/TUDataset', name='Cuneiform', transform=T.Compose([my_normalization()]))\n",
        "augmentation_dataset = TUDataset(root='data/TUDataset', name='Cuneiform', transform=T.Compose([my_affine_transforms(), my_normalization()]))\n",
        "\n",
        "# np.random.seed(12345)\n",
        "model = None\n",
        "\n",
        "for i in range(1,11):\n",
        "  results.append({})\n",
        "  tstamps.append([])\n",
        "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
        "  # if fold != 0:\n",
        "  #   continue\n",
        "  # Print\n",
        "  print(f'FOLD {fold}')\n",
        "  print('--------------------------------')\n",
        "\n",
        "  tstamps[fold].append(datetime.now())\n",
        "\n",
        "  del model \n",
        "  model = Net()\n",
        "\n",
        "  if early_stopping:\n",
        "    if np_random:\n",
        "      np.random.shuffle(train_ids)\n",
        "    \n",
        "    val_size = len(train_ids) // 15\n",
        "    val_ids = list(train_ids[:val_size])\n",
        "    train_ids = list(train_ids[val_size:])\n",
        "    val_loader = DataLoader(dataset[val_ids], batch_size=batch_size)\n",
        "\n",
        "    dataset = TUDataset(root='data/TUDataset', name='Cuneiform', transform=T.Compose([my_normalization()]))\n",
        "    # augmentation_dataset = TUDataset(root='data/TUDataset', name='Cuneiform', transform=T.Compose([my_affine_transforms(), my_normalization()]))\n",
        "\n",
        "    test_loader = DataLoader(dataset[test_ids], batch_size=batch_size)\n",
        "    # val_loader = test_loader # DataLoader(dataset[test_ids], batch_size=batch_size)\n",
        "    train_loader = DataLoader(dataset[train_ids], batch_size=batch_size)\n",
        "    augmented_train_loader = DataLoader(augmentation_dataset[train_ids], batch_size=batch_size)\n",
        "\n",
        "    # model.apply(reset_weights)    \n",
        "    early_stop_callback = EarlyStopping(monitor=\"val_acc_epoch\", \n",
        "                                        min_delta=0.00, \n",
        "                                        patience=1000, \n",
        "                                        verbose=False, \n",
        "                                        mode=\"max\")\n",
        "    checkpoint_callback = ModelCheckpoint(dirpath=\"checkpoints\",\n",
        "                                          filename=\"best-checkpoint-fold-\"+str(fold),\n",
        "                                          save_top_k=1,\n",
        "                                          verbose=False,\n",
        "                                          monitor=\"val_acc_epoch\",\n",
        "                                          mode=\"max\",\n",
        "                                          every_n_epochs = 1,\n",
        "                                          save_last=True)\n",
        "\n",
        "    logger = TensorBoardLogger(\"lightning_logs\", name=\"model\", default_hp_metric= False)\n",
        "    trainer = pl.Trainer(gpus=1, # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "                        logger=logger,\n",
        "                        callbacks=[early_stop_callback, checkpoint_callback], \n",
        "                        # callbacks=[checkpoint_callback], \n",
        "                        check_val_every_n_epoch=1,\n",
        "                        max_epochs=max_epochs)\n",
        "    trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
        "    \n",
        "    checkpoint = torch.load(\"/content/checkpoints/best-checkpoint-fold-\"+str(fold)+\".ckpt\")\n",
        "    model.load_state_dict(checkpoint['state_dict'])  \n",
        "  else:  \n",
        "    if np_random:\n",
        "      np.random.shuffle(train_ids)\n",
        "\n",
        "    test_loader = DataLoader(dataset[test_ids], batch_size=batch_size)\n",
        "    train_loader = DataLoader(dataset[train_ids], batch_size=batch_size)\n",
        "    augmented_train_loader = DataLoader(augmentation_dataset, batch_size=batch_size)\n",
        "\n",
        "    model.apply(reset_weights)\n",
        "\n",
        "    logger = TensorBoardLogger(\"lightning_logs\", name=\"model\", default_hp_metric= False)\n",
        "    trainer = pl.Trainer(gpus=1,# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!11 \n",
        "                         logger=logger, \n",
        "                         check_val_every_n_epoch=1, \n",
        "                         max_epochs=max_epochs,\n",
        "                         replace_sampler_ddp=True,\n",
        "                         )\n",
        "\n",
        "    trainer.fit(model=model, train_dataloaders=train_loader)\n",
        "\n",
        "    # trainer.fit(model=model, train_dataloader=augmented_train_loader)\n",
        "  # ---------------------- #  \n",
        "\n",
        "  # Завантажує кращу модель у фолді, і проводить тест на ній.\n",
        "    \n",
        "  tstamps[fold].append(datetime.now())\n",
        "  # results.append({})\n",
        "  results[fold]['epoch'] = model.current_epoch\n",
        "  results[fold]['accuracy'] = trainer.test(model=model, dataloaders=test_loader)\n",
        "  print(results[fold])\n",
        "  with open(p, 'w') as f:\n",
        "    f.write(str(results))\n",
        "    f.write(\"\\n\\n\")\n",
        "    f.write(str(tstamps))\n",
        "  # if fold == 0:\n",
        "  #   break;\n",
        "\n",
        "!cp -r /content/checkpoints/ /content/drive/MyDrive/Masters/checkpoints+$(date +\"%Y-%m-%d-%T\")\n",
        "!cp -r lightning_logs/model/ /content/drive/MyDrive/Masters/lightning_logs+$(date +\"%Y-%m-%d-%T\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7Swtac2UqGA",
        "outputId": "0f17ebc0-469e-4bf3-9805-64fd0c6ab608"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-1daadb5c-79ae-8bb2-7110-32ec9c13d2e5)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w08WSFSVWfeh",
        "outputId": "18347e95-4ca5-4c04-aa8a-a65385154171"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Apr 10 12:01:46 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Masters_codelisting.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}